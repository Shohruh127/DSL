{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "GO_kXfq6sCsg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "from math import sqrt\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "bISAEE6oYeFT"
      },
      "outputs": [],
      "source": [
        "def parse_tempo(val):\n",
        "    \"\"\"\n",
        "    Converts tempo from string/object (like '[129.19921875]') to float.\n",
        "    Returns np.nan if parsing fails.\n",
        "    \"\"\"\n",
        "    val_str = str(val).strip(\"[]\")\n",
        "    try:\n",
        "        return float(val_str)\n",
        "    except:\n",
        "        return np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwAT6ngjsQTf",
        "outputId": "ad24f0dd-9153-416d-b02a-f9fe5d7fef90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial shape of data: (2933, 38)\n",
            "Numeric columns: ['Id', 'sampling_rate', 'age', 'mean_pitch', 'max_pitch', 'min_pitch', 'jitter', 'shimmer', 'energy', 'zcr_mean', 'spectral_centroid_mean', 'tempo', 'hnr', 'num_words', 'num_characters', 'num_pauses', 'silence_duration', 'pitch_mean', 'pitch_std', 'pitch_iqr', 'f1_mean', 'f2_mean', 'f3_mean', 'f2_f1_ratio', 'hnr_mean', 'jitter.1', 'shimmer.1', 'speech_rate', 'pause_duration_std', 'spectral_flux', 'rolloff_25', 'rolloff_75', 'mfcc1_mean', 'mfcc1_std', 'mfcc2_mean']\n"
          ]
        }
      ],
      "source": [
        "# 1. Load the dataset\n",
        "data_path = \"/content/drive/MyDrive/DSL_Winter_Project_2025/development_with_core_features.csv\"\n",
        "data = pd.read_csv(data_path)\n",
        "print(\"Initial shape of data:\", data.shape)\n",
        "\n",
        "# 2. Parse 'tempo' so it becomes numeric\n",
        "data[\"tempo\"] = data[\"tempo\"].apply(parse_tempo)\n",
        "\n",
        "# 3. Identify all numeric columns\n",
        "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(\"Numeric columns:\", numeric_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "w7QyIpXGG64D"
      },
      "outputs": [],
      "source": [
        "df_numeric = data[numeric_cols].copy()  # Subset with only numeric columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HLv4n0gJG6vt",
        "outputId": "7b2da94a-83e1-4639-93a9-7b19cecec62f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined correlation (Spearman & Pearson) to 'age':\n",
            "                         spearman   pearson  abs_spearman  abs_pearson\n",
            "silence_duration        0.587651  0.514127      0.587651     0.514127\n",
            "num_words               0.555482  0.473499      0.555482     0.473499\n",
            "num_characters          0.555298  0.473403      0.555298     0.473403\n",
            "hnr                    -0.532629 -0.446880      0.532629     0.446880\n",
            "num_pauses              0.532293  0.437670      0.532293     0.437670\n",
            "max_pitch               0.469464  0.226643      0.469464     0.226643\n",
            "min_pitch              -0.464523 -0.224201      0.464523     0.224201\n",
            "jitter.1               -0.459493 -0.369446      0.459493     0.369446\n",
            "zcr_mean                0.367529  0.278430      0.367529     0.278430\n",
            "mean_pitch              0.366192  0.315645      0.366192     0.315645\n",
            "pitch_mean              0.362789  0.316161      0.362789     0.316161\n",
            "jitter                  0.349202  0.238498      0.349202     0.238498\n",
            "pitch_iqr               0.331967  0.306855      0.331967     0.306855\n",
            "pitch_std               0.284495  0.283103      0.284495     0.283103\n",
            "pause_duration_std      0.271759  0.172975      0.271759     0.172975\n",
            "shimmer                 0.263198  0.204140      0.263198     0.204140\n",
            "mfcc2_mean             -0.259435 -0.209287      0.259435     0.209287\n",
            "rolloff_25              0.225734  0.155494      0.225734     0.155494\n",
            "f3_mean                -0.221409 -0.159753      0.221409     0.159753\n",
            "spectral_flux          -0.210285 -0.225082      0.210285     0.225082\n",
            "energy                  0.194470  0.020892      0.194470     0.020892\n",
            "rolloff_75             -0.180916 -0.157591      0.180916     0.157591\n",
            "f2_mean                -0.169830 -0.086090      0.169830     0.086090\n",
            "shimmer.1               0.119274  0.085257      0.119274     0.085257\n",
            "hnr_mean                0.116882  0.015043      0.116882     0.015043\n",
            "speech_rate            -0.096987 -0.107533      0.096987     0.107533\n",
            "f1_mean                -0.084589  0.005331      0.084589     0.005331\n",
            "f2_f1_ratio            -0.066365 -0.065385      0.066365     0.065385\n",
            "mfcc1_std               0.061257  0.027904      0.061257     0.027904\n",
            "spectral_centroid_mean  0.053357  0.044899      0.053357     0.044899\n",
            "mfcc1_mean              0.024899  0.021063      0.024899     0.021063\n",
            "Id                      0.024374  0.024825      0.024374     0.024825\n",
            "tempo                  -0.009213 -0.040547      0.009213     0.040547\n",
            "sampling_rate                NaN       NaN           NaN          NaN\n"
          ]
        }
      ],
      "source": [
        "# Correlation with the target using Spearman\n",
        "corr_spearman = df_numeric.corr(method=\"spearman\")[\"age\"].drop(\"age\")\n",
        "# Correlation with the target using Pearson\n",
        "corr_pearson = df_numeric.corr(method=\"pearson\")[\"age\"].drop(\"age\")\n",
        "\n",
        "# Combine into a single DataFrame\n",
        "df_corr = pd.DataFrame({\n",
        "    \"spearman\": corr_spearman,\n",
        "    \"pearson\": corr_pearson\n",
        "})\n",
        "df_corr[\"abs_spearman\"] = df_corr[\"spearman\"].abs()\n",
        "df_corr[\"abs_pearson\"] = df_corr[\"pearson\"].abs()\n",
        "\n",
        "df_corr.sort_values(\"abs_spearman\", ascending=False, inplace=True)\n",
        "\n",
        "print(\"Combined correlation (Spearman & Pearson) to 'age':\\n\", df_corr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WCvXPXfFG6rT",
        "outputId": "eb8314b5-b754-448a-b7c1-98186b6b9b52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features kept after correlation filtering:\n",
            " ['silence_duration', 'num_words', 'num_characters', 'hnr', 'num_pauses', 'max_pitch', 'min_pitch', 'jitter.1', 'zcr_mean', 'mean_pitch', 'pitch_mean', 'jitter', 'pitch_iqr', 'pitch_std', 'pause_duration_std', 'shimmer', 'mfcc2_mean', 'rolloff_25', 'f3_mean', 'spectral_flux', 'energy', 'rolloff_75', 'f2_mean', 'shimmer.1', 'hnr_mean', 'speech_rate']\n",
            "Before filtering: (2933, 34)\n",
            "After filtering: (2933, 26)\n"
          ]
        }
      ],
      "source": [
        "threshold = 0.1  # correlation threshold\n",
        "\n",
        "# Condition to keep a feature:\n",
        "#    (abs_spearman >= threshold) OR (abs_pearson >= threshold)\n",
        "# We want to DROP if both are below threshold, i.e.\n",
        "#    (abs_spearman < 0.1) AND (abs_pearson < 0.1)\n",
        "# We'll invert the condition to pick the features we keep\n",
        "keep_condition = (\n",
        "    (df_corr[\"abs_spearman\"] >= threshold) |\n",
        "    (df_corr[\"abs_pearson\"] >= threshold)\n",
        ")\n",
        "\n",
        "features_to_keep = df_corr[keep_condition].index.tolist()\n",
        "print(\"Features kept after correlation filtering:\\n\", features_to_keep)\n",
        "\n",
        "# Now remove features not in keep list from your data (excluding 'age')\n",
        "X = df_numeric.drop(columns=[\"age\"])  # if you have separate features\n",
        "X_filtered = X[features_to_keep]\n",
        "print(\"Before filtering:\", X.shape)\n",
        "print(\"After filtering:\", X_filtered.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "19YOiBbOG6oL"
      },
      "outputs": [],
      "source": [
        "def remove_high_corr_columns_across_methods(X, threshold=0.8, target_corr_df=None):\n",
        "    \"\"\"\n",
        "    Remove columns from DataFrame X that are highly correlated\n",
        "    (above 'threshold') in ANY of the two correlation measures:\n",
        "    Pearson, Spearman.\n",
        "\n",
        "    We handle columns pairwise. If correlation is > threshold\n",
        "    for a given pair, we drop one of them (the one with lower\n",
        "    correlation to the target).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : pd.DataFrame\n",
        "        The DataFrame with only the columns to be processed.\n",
        "    threshold : float, default=0.8\n",
        "        Correlation threshold above which columns are considered\n",
        "        highly correlated.\n",
        "    target_corr_df : pd.DataFrame or None, default=None\n",
        "        If provided, should contain each column's correlation\n",
        "        to the target (e.g. 'abs_spearman', 'abs_pearson').\n",
        "        We'll use it to decide which column to remove\n",
        "        when a pair is above threshold.\n",
        "        If None, we remove the second column by default.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X_filtered : pd.DataFrame\n",
        "        The DataFrame with columns removed.\n",
        "    features_to_remove : set\n",
        "        The set of columns that were removed.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Compute correlation matrices for the 3 methods\n",
        "    corr_pearson = X.corr(method='pearson').abs()\n",
        "    corr_spearman = X.corr(method='spearman').abs()\n",
        "\n",
        "    # 2. Combine them by taking the maximum correlation\n",
        "    #    across pearson, spearman, kendall for each pair\n",
        "    max_corr = np.minimum.reduce([corr_pearson.values,\n",
        "                                  corr_spearman.values])\n",
        "\n",
        "    # Convert back to a DataFrame for convenience\n",
        "    max_corr_df = pd.DataFrame(max_corr,\n",
        "                               index=X.columns,\n",
        "                               columns=X.columns)\n",
        "\n",
        "    features_to_remove = set()\n",
        "    columns = list(X.columns)\n",
        "\n",
        "    # 3. Identify pairs with correlation above threshold\n",
        "    for i in range(len(columns)):\n",
        "        for j in range(i+1, len(columns)):\n",
        "            if max_corr_df.iloc[i, j] > threshold:\n",
        "                colname1 = columns[i]\n",
        "                colname2 = columns[j]\n",
        "\n",
        "                # Skip if either column is already removed\n",
        "                if colname1 in features_to_remove or colname2 in features_to_remove:\n",
        "                    continue\n",
        "\n",
        "                # Decide which column to remove\n",
        "                if target_corr_df is not None:\n",
        "                    # We have correlation to the target; remove the column with lower correlation\n",
        "                    col1_abs = target_corr_df.loc[colname1] if colname1 in target_corr_df.index else 0\n",
        "                    col2_abs = target_corr_df.loc[colname2] if colname2 in target_corr_df.index else 0\n",
        "                    if col1_abs < col2_abs:\n",
        "                        features_to_remove.add(colname1)\n",
        "                    else:\n",
        "                        features_to_remove.add(colname2)\n",
        "                else:\n",
        "                    # If no target info, remove colname2 by default\n",
        "                    features_to_remove.add(colname2)\n",
        "\n",
        "    # 4. Drop the identified columns\n",
        "    X_filtered = X.drop(columns=features_to_remove, errors='ignore')\n",
        "\n",
        "    return X_filtered, features_to_remove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPeYbuvXHc3E",
        "outputId": "03a6d623-0bfc-4c0f-b39a-739c4ad6dc66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns removed due to high correlation:\n",
            "{'pitch_iqr', 'num_words', 'rolloff_25', 'hnr_mean', 'pitch_mean', 'num_characters', 'mean_pitch'}\n"
          ]
        }
      ],
      "source": [
        "# Unpack the results\n",
        "X_final, features_to_remove = remove_high_corr_columns_across_methods(\n",
        "    X_filtered,\n",
        "    threshold=0.8,\n",
        "    target_corr_df=df_numeric[\"age\"]\n",
        ")\n",
        "\n",
        "# Print only the columns that were removed\n",
        "print(\"Columns removed due to high correlation:\")\n",
        "print(features_to_remove)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "OEX649LMLkcd"
      },
      "outputs": [],
      "source": [
        "# 1. Identify top 1 most frequent ethnicities\n",
        "top_1 = data['ethnicity'].value_counts().nlargest(1).index\n",
        "\n",
        "# 2. Replace everything not in top_1 with \"Other\"\n",
        "data['ethnicity'] = data['ethnicity'].apply(\n",
        "    lambda x: x if x in top_1 else \"Other\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "shYzwh9osRtv",
        "outputId": "2a75e900-46f0-464f-8d1d-138fff2a415c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features shape: (2933, 21)\n",
            "Target shape: (2933,)\n"
          ]
        }
      ],
      "source": [
        "# 5. Separate features (X) and target (y)\n",
        "X_final[\"gender\"] = data[\"gender\"]\n",
        "X_final[\"ethnicity\"] = data[\"ethnicity\"]\n",
        "\n",
        "X = X_final\n",
        "y = data[\"age\"]\n",
        "\n",
        "# Just to confirm we don't have these columns in X:\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Target shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "collapsed": true,
        "id": "nvj3a7n5sTA1"
      },
      "outputs": [],
      "source": [
        "# Potential categorical columns\n",
        "categorical_cols = [\"gender\", \"ethnicity\"]\n",
        "\n",
        "# 'tempo' is now numeric (float), I include it with other numeric columns\n",
        "all_feature_cols = X.columns.tolist()\n",
        "numeric_cols_for_pipeline = [col for col in all_feature_cols if col not in categorical_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "INpj8E9vs8GD"
      },
      "outputs": [],
      "source": [
        "# Update the numeric transformer to include imputation\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')), # or 'median'\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Categorical transformer\n",
        "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "# Combined column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_cols_for_pipeline),\n",
        "        (\"cat\", categorical_transformer, categorical_cols)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "gP47V3c0M0YK"
      },
      "outputs": [],
      "source": [
        "max_iter_options = [100, 200, 300]\n",
        "learning_rate_options = [0.01, 0.05, 0.1]\n",
        "max_depth_options = [3, 5, 7, None]\n",
        "min_samples_leaf_options = [10, 20]\n",
        "\n",
        "best_rmse = float(\"inf\")\n",
        "best_params = None\n",
        "best_model = None\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1,     # 10% validation split\n",
        ")\n",
        "# Defining hist_pipeline outside the loop\n",
        "hist_pipeline = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"hist_gbr\", HistGradientBoostingRegressor(random_state=42))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xb_rxk2GCRxf",
        "outputId": "86674a79-827a-4e34-bdff-fd948e03130f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Params: {'hist_gbr__max_iter': 300, 'hist_gbr__learning_rate': 0.01, 'hist_gbr__max_depth': 5, 'hist_gbr__min_samples_leaf': 20}\n",
            "Best Validation RMSE: 10.1285\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['best_hist_gbr.pkl']"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for max_iter in max_iter_options:\n",
        "    for lr in learning_rate_options:\n",
        "        for depth in max_depth_options:\n",
        "            for leaf in min_samples_leaf_options:\n",
        "                # Create a fresh pipeline each iteration\n",
        "                hist_pipeline = Pipeline(steps=[\n",
        "                    (\"preprocessor\", preprocessor),\n",
        "                    (\"hist_gbr\", HistGradientBoostingRegressor(random_state=42))\n",
        "                ])\n",
        "\n",
        "                params = {\n",
        "                    \"hist_gbr__max_iter\": max_iter,\n",
        "                    \"hist_gbr__learning_rate\": lr,\n",
        "                    \"hist_gbr__max_depth\": depth,\n",
        "                    \"hist_gbr__min_samples_leaf\": leaf,\n",
        "                }\n",
        "                hist_pipeline.set_params(**params)\n",
        "\n",
        "                # Fit on training data\n",
        "                hist_pipeline.fit(X_train, y_train)\n",
        "\n",
        "                # Predict on validation data\n",
        "                y_val_pred = hist_pipeline.predict(X_val)\n",
        "\n",
        "                # Compute RMSE\n",
        "                mse = mean_squared_error(y_val, y_val_pred)\n",
        "                rmse = sqrt(mse)\n",
        "\n",
        "                # Check if this is the best so far\n",
        "                if rmse < best_rmse:\n",
        "                    best_rmse = rmse\n",
        "                    best_params = params\n",
        "                    # Store THIS pipeline (with current fitted state)\n",
        "                    best_model = hist_pipeline\n",
        "\n",
        "# Final: print the best parameters and RMSE\n",
        "print(\"Best Params:\", best_params)\n",
        "print(f\"Best Validation RMSE: {best_rmse:.4f}\")\n",
        "\n",
        "# Optional: save the best HistGradientBoosting model\n",
        "joblib.dump(best_model, \"best_hist_gbr.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AJcIo1CVER9p",
        "outputId": "3a374eb6-b43a-45d6-b390-c6f0787a52e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best SVR Params: {'svr__kernel': 'rbf', 'svr__C': 100, 'svr__gamma': 0.01}\n",
            "Best SVR Validation RMSE: 10.5468\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['best_svr_model.pkl']"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example hyperparameter grid\n",
        "kernel_options = [\"rbf\", \"poly\"]\n",
        "C_options = [1, 10, 100]\n",
        "gamma_options = [0.1, 0.01, \"auto\"]\n",
        "\n",
        "best_rmse = float(\"inf\")\n",
        "best_params = None\n",
        "best_model = None\n",
        "\n",
        "for kernel in kernel_options:\n",
        "    for C_value in C_options:\n",
        "        for gamma_val in gamma_options:\n",
        "            # 1. Build a fresh pipeline for each iteration\n",
        "            svr_pipeline = Pipeline(steps=[\n",
        "                (\"preprocessor\", preprocessor),  # your ColumnTransformer or numeric/categorical pipeline\n",
        "                (\"svr\", SVR())\n",
        "            ])\n",
        "\n",
        "            # 2. Set params for SVR within the pipeline\n",
        "            params = {\n",
        "                \"svr__kernel\": kernel,\n",
        "                \"svr__C\": C_value,\n",
        "                \"svr__gamma\": gamma_val\n",
        "            }\n",
        "            svr_pipeline.set_params(**params)\n",
        "\n",
        "            # 3. Fit on training data\n",
        "            svr_pipeline.fit(X_train, y_train)\n",
        "\n",
        "            # 4. Predict on validation data\n",
        "            y_val_pred_svr = svr_pipeline.predict(X_val)\n",
        "\n",
        "            # 5. Compute RMSE\n",
        "            mse_svr = mean_squared_error(y_val, y_val_pred_svr)\n",
        "            rmse_svr = sqrt(mse_svr)\n",
        "\n",
        "            # 6. Check if this is the best so far\n",
        "            if rmse_svr < best_rmse:\n",
        "                best_rmse = rmse_svr\n",
        "                best_params = params\n",
        "                # Store this trained pipeline in its current state\n",
        "                best_model = svr_pipeline\n",
        "\n",
        "# Final: print the best parameters and RMSE\n",
        "print(\"Best SVR Params:\", best_params)\n",
        "print(f\"Best SVR Validation RMSE: {best_rmse:.4f}\")\n",
        "\n",
        "# Optional: save the best SVR model\n",
        "joblib.dump(best_model, \"best_svr_model.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "k97sGjjC5CtY"
      },
      "outputs": [],
      "source": [
        "eval_data_path = \"/content/drive/MyDrive/DSL_Winter_Project_2025/evaluation_with_core_features.csv\"\n",
        "eval_data = pd.read_csv(eval_data_path)\n",
        "# Clean & transform\n",
        "eval_data['gender'] = eval_data['gender'].replace({'famale': 'female'})\n",
        "eval_data[\"tempo\"] = eval_data[\"tempo\"].apply(parse_tempo)\n",
        "eval_data[\"ethnicity\"] = eval_data[\"ethnicity\"].apply(\n",
        "    lambda x: x if x in top_1 else \"Other\"\n",
        ")\n",
        "\n",
        "# Select final columns\n",
        "final_cols = [\n",
        "    \"silence_duration\", \"hnr\", \"num_pauses\", \"max_pitch\", \"min_pitch\",\n",
        "    \"jitter.1\", \"zcr_mean\", \"jitter\", \"pitch_std\", \"pause_duration_std\",\n",
        "    \"shimmer\", \"mfcc2_mean\", \"f3_mean\", \"spectral_flux\", \"energy\",\n",
        "    \"rolloff_75\", \"f2_mean\", \"shimmer.1\", \"speech_rate\", \"gender\",\n",
        "    \"ethnicity\"\n",
        "]\n",
        "X_eval = eval_data[final_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzfSnN8mL8hp",
        "outputId": "399b1f98-263b-470c-85f0-633147de42a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission file saved as 'submission_hist.csv'\n"
          ]
        }
      ],
      "source": [
        "# Load Hist model\n",
        "best_model = joblib.load(\"best_hist_gbr.pkl\")\n",
        "# Predict\n",
        "preds = best_model.predict(X_eval)\n",
        "\n",
        "# Create submission\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": eval_data[\"Id\"],\n",
        "    \"Predicted\": preds.round()\n",
        "})\n",
        "submission.to_csv(\"submission_hist.csv\", index=False)\n",
        "print(\"Submission file saved as 'submission_hist.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "collapsed": true,
        "id": "-XwIUJv75Igu"
      },
      "outputs": [],
      "source": [
        "# Load SVR model\n",
        "best_model = joblib.load(\"best_svr_model.pkl\")\n",
        "\n",
        "# Predict\n",
        "y_eval_pred = best_model.predict(X_eval)\n",
        "\n",
        "# Create submission\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": eval_data[\"Id\"],\n",
        "    # Round to nearest integer\n",
        "    \"Predicted\": y_eval_pred.round()\n",
        "})\n",
        "submission.to_csv(\"submission_svr.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "8JPxlJllTwcE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
